---
layout:     post
title:      "基于对抗训练的远程弱监督事件抽取"
subtitle:   "Adversarial Training for Weakly Supervised Event Detection"
date:       2019-08-05 10:00:00
author:     "Wwt"
header-img: "img/adversarial/bg.png"
catalog: true
tags:   
    - 事件抽取
    - 对抗训练
    - 弱监督
---

本文主要关注将弱监督方法应用到事件抽取（Event Detection）中，并利用对抗训练，来解决人工标注耗时耗力的问题，通过自动标注数据获得了显著的效果。以往的方法通常依赖于复杂的预定义规则和知识库中的现有示例来标注信息，该方法容易遭受覆盖面不广、主题偏差和数据噪声的影响。为了解决上述问题，我们构建了一个大规模且覆盖面较广的相关事件数据集，然后应用对抗训练机制来识别候选集的信息实例，同时过滤到那些噪声实例。实验结果表明，我们提出的候选选择和对抗训练可以协同工作，为事件抽取提供了更加多样化和准确的数据。

### 背景

事件抽取旨在识别句中的触发词，并为触发词分配类型，触发词一般激活了某个事件实例，表示事件真实发生。大多数事件抽取方法是基于特征工程，例如词级特征和结构特征。随着深度学习的发展，越来越多的方法直接将文本信息编码到一个低维空间来识别触发词，这些基于人工标注数据的有监督方法，数据规模成为了提升性能的瓶颈。

弱监督被广泛采用来扩充原始训练数据，与有监督方法相比，弱监督方法可以有效推广并应用于现实的事件探测任务而无需大量的劳动。但目前的弱监督方法仍存在以下几个问题：

1. 弱监督方法自然受到数据中不可避免的噪声影响；
2. 当前弱监督ED模型采用复杂的预定义规则和不完整的知识库来自动获取数据，从而产生具有低覆盖率和主题偏差的标记数据。

为了解决上述问题，我们提出一种简单的基于触发词隐式实例的发现策略，做出如下假设：如果给定短语作为已知实例的触发词，则所有提及该词的实例可以表示为事件。与复杂的规则相比，该策略的优势在单词，触发词和事件类型之间的相关性方面限制较少。因此，我们的策略可以获得涵盖更多主题和实例的候选集，而无需手动设计规则。

我们进一步引入对抗训练机制，不仅可以从候选集中提取信息实例，还可以在类似远程监督等嘈杂场景中提高事件探测模型的性能。我们将数据集划分为可靠集合不可靠集合，并设计了一个判别器合生成器。判别器用于判断给定实例是否具有正确的标注信息，并且生成器用来从原始数据中生成最具有迷惑性的实例来欺骗判别器。判别器使用可靠数据作为正实例进行训练，将生成器生成的数据作为负例书记进行训练。同时，训练生成器生成数据来欺骗判别器。在训练过程中，生成器可以提供大量潜在噪声数据来增强判别器，判别器可以影响生成器生成更具信息性的数据。由于噪声胜局对优化生成器和判别器没有影响，当生成器和判别器达到平衡时，判别器可以提高对噪声的干扰并更好地对事件进行分类，并且生成器可以为判别器提供有效的信息实例。

### 方法

![1](/img/adersarial/1.png)

如上图所示，模型的整个框架包含三个模块：实例编码，对抗训练策略和各种适用事件探测的远程监督情景。

#### 实例编码

实例编码模块主要将输入实例转换成对应的词向量矩阵，然后将词向量送入到上层网络进行编码，这里我们选择CNN和BERT作为编码表示层。CNN对输入实例的所有词向量进行表示学习，输入包含了词向量和位置向量，位置向量表示句子中的每个词与候选触发词的相对距离。经过卷积操作后获得隐层向量：

$$
\{h_1,h_2,...,h_n\}=CNN(w_1,w_2,...,w_n)
$$


BERT与CNN类似，对输入句子$x$中的所有切片和位置向量进行求和操作。BERT采用多层双向transform编码来获得隐层向量表示：

$$
\{h_1,h_2,...,h_n\}=BERT(w_1,w_2,...,w_n)
$$


由于候选触发词$t$将输入句子$x$划分成两部分，我们对隐层向量使用动态多池化技术来获得实例向量$x$:

$$
[\overleftarrow{x}]_j=max\{[h_1]_j,...,[h_i]_j\} \\ [\overrightarrow{x}]_j=max\{[h_{i+1}]_j,...,[h_n]_j\}\\x=[\overleftarrow{x};\overrightarrow{x}]
$$


其中$[·] j$是向量的第$j$个值，$i$是触发器$t$的位置。 由于CNN和BERT采用动态多池操作，我们在本文中将它们命名为“DMCNN”和“DMBERT”。

#### 对抗训练

如上图所示，对抗训练策略包含了一个判别器和生成器。判别器是对实例中的触发词进行探测以及识别事件类型。当输入一个噪声实例，判别器会抵抗噪音并明确指出该实例中没有触发词和事件。生成器用于从不可靠的数据集中选择实例来尽可能地混淆判别器的判断。

假设每个实例$x\in R$明确地表示了其标记触发器$t$和事件类型$e$。 相反，在对抗训练期间，假设每个实例$x\in U$是不可信的，即存在一定的概率，即它被错误地标记。 因此，我们设计判别器来判断给定实例是否可以表现其标记事件类型，其目的在于最大化条件概率$P(e \mid x，t)$，$x\in R$和$1-P(e \mid x，t )，x \in U$。 训练发生器以从$U$中选择最混乱的实例以欺骗鉴别器，即通过$P(e \mid x，t)，x\in U$选择实例。 训练过程是一个最小-最大的对抗游戏。
$$
\phi_D=max(E_{x\sim P_R}[P(e\mid x,t)])\\
+E_{x\sim P_{u}}[log-P(e\mid x,t)] \\
\phi_G=max E_{x \sim P_u}[log(P(e\mid x,t))]
$$
其中$P_R$是可靠的数据分布，并且生成器根据概率分布$P_u$从不可靠数据中采样对抗性示例。 虽然$\phi _D$和$\phi_G$是相互矛盾的，但是$U$中的噪声数据对$\phi_D$和$\phi_G$都有影响。 因此，当生成器和判别器在经过充分训练后达到平衡时，生成器倾向于选择具有较高概率的信息实例，与那些有噪声的实例相比，增强了判别器对噪声的抵抗能力并且可以更好地分类事件。

#### 判别器

给定实例$x$及其标记的触发器$t$和事件类型$e$，判别器负责判断给定实例是否表现其标记的触发器和事件类型。 在用嵌入$x$表示实例$x$之后，我们实现了如下的判别器：
$$
D(e\mid x,t) =e.x\\
P(e\mid x,t)=\frac{exp(D(e\mid x,t))}{\sum_{\hat{e}\in \varepsilon}exp(D(\hat{e}\mid x,t))}
$$


其中$e$是事件类型$e\in E$的嵌入。优化的判别器将为$R$中的那些实例分配高分，同时不相信那些在$U$中实例及其标签。因此，在实际训练中，我们将判别器的损失函数优化形式调整如下，
$$
\zeta_D = -\sum_{x\in R}\frac{1}{\mid R\mid}log(P(e\mid x,t))-\sum_{x\in u}P_u(x)log(1-P(e\mid x,t)))
$$


在优化判别器时，我们将编码器的分量和$D（e \mid x，t）$视为更新的参数。 该损失函数$\zeta_D$对应上述等式中的$\phi_D$。

#### 生成器

该生成器旨在从$U$中选择最容易混淆的实例来欺骗判别器。 我们设计生成器通过优化概率分布$P_u$来选择实例。 生成器计算所有实例的混淆分数来评估其困惑并进一步计算混淆概率$p_u$，如下所示：

$$
f(x)=W*x+b \\
p_u(x)=\frac{exp(f(x))}{\sum_{\hat{x}\in u}exp(f(\hat{x}))}
$$
其中$x$是实例$X$经过编码器后的输出，$W$和$b$是超参数。

我们认为通过鉴别器计算的实例得分越高，该实例就越混淆，因为它们更可能欺骗判别器做出错误的决定。 我们希望优化生成器能够更加关注那些最令人困惑的实例。 因此，给定一个实例$x\in U$和不可靠标记的触发器$t$和事件类型$e$，我们通过定义以下损失函数来优化生成器，如下所示
$$
\zeta_G=-\sum_{x\in u}P_u(x)log(P(e\mid x,t))
$$
其中，$P(e\mid x,t)$由生成器计算得来。

在$U$中可能存在一些实例标记为$NA$，并且这些实例总是被错误地预测到其它一些事件中。 因此，我们专门使用所有已标记事件的平均分数来表示$P（e \mid x，t）$，如下所示：
$$
P(NA\mid x,t) =\frac{1}{\varepsilon-1}\sum_{e \in \varepsilon,e \neq NA}P(e\mid x,t)
$$
其中$\epsilon$表示事件类型的集合。

#### 远程监督

为了利用未标注的数据，我们提出了一种简单的基于触发词的潜在实例发现策略，该策略可以自动标记原始数据的触发词和事件类型。 该策略基于启发式假设，即如果给定单词在已知实例中充当触发词，则在**原始数据中**提及该单词的所有其它实例都是潜在的实例并且还可以表示为事件。 例如，“**married**”这个词在**“Mark Twain and Olivia Langdon married in 1870”**中作为触发词激活了“结婚”事件，然后未标记数据中的所有包含“married”一词的实例将被加入潜在候选实例集合中。与现有弱监督ED模型中使用的复杂规则相比，我们基于触发器的潜在实例发现策略很简单，无需考虑单词，触发词和事件类型之间的相关性。由于我们的策略限制较少，因此在没有任何额外手动设计的情况下，可以有效和高效的获得大规模候选集。同时，**候选集可以覆盖比现有策略更多的实例和主题**。

#### 半监督情景

在针对半监督场景，我们调整对抗训练策略，首先使用小规模标记数据预先训练编码器和判别器，以使它们能够在一定程度上检测事件触发词并识别事件类型。然后，基于我们的实例发现策略构建一个**大规模的潜在候选集合**，标记数据中的触发词作为启发式种子。我们使用预训练的编码器和判别器来自动标记候选集中所有实例的触发词和事件类型，以构建噪声大的数据。将小规模标记数据作为可靠集$R$，将大规模自动标记数据作为不可靠集$U$，可以一起优化编码器。判别器和生成器进行对抗训练。在对抗训练期间，当判别器和生成器在经过某些训练时期之后达到平衡时，所有来自不可靠数据集$U$的实例由生成器推荐并被判别器正确标记的，将从$U$调整到$R$中迭代地进行对抗训练，可以识别出信息实例并滤除$U$中的噪声实例，并完成利用大规模未标记数据来丰富小规模标记数据。

#### 远程监督

远程监督场景的适用方法类似于半监督场景。 我们首先使用整个自动标记数据来预先跟踪编码器和判别器。 然后，编码器和判别器用于计算自动标记集中所有实例的置信分数。 通过设置特定阈值，我们可以将整个自动标记的集合分成两部分。 分数高于阈值的实例将被添加到可靠集$R$中，具有较低分数的其他实例将被添加到不可靠集$U$中。在整个自动标记集被分成$R$和$U$之后，我们可以进行对抗性训练，以减少$U$中那些噪音的影响，增强判别器的识别能力，以便更好地识别事件。 直观地来看，可靠集$R$与自动标注集合分离，并且作为种子利用更多原始数据。

### 实验结果

论文中的实验部分描述十分详细，感兴趣的话可以去看原文，这里我只列出了总体性能。

![2](/img/adersarial/2.png)

通过上表我们可以发现：(1)我们的DMCNN+Boot模型与ANN-FN和DLRNN获得了相当性能，但ANN-FN和DLRNN设计了复杂结构来利用其它信息。结果表明，我们的方法可以构建高质量的数据集，没有复杂的规则和大规模的基础知识，并且可以有效地收集有益于训练模型的各种实例；(2)DMBERT和DMBERT + Boot在所有模型中都获得了最佳性能。 这受利于BERT的有效架构和大规模预训练信息，以及ED的动态多池化机制。 我们的方法增加了训练数据，进一步增强了BERT，从而实现更好的性能并展示出我们模型的有效性。

论文中还对基于触发词实例的发现和对抗训练策略构建的数据集质量进行评估，通过实验结果发现利用论文提出的模型结构构件数据集的精确度与现有的重要监督方法相当，甚至在第一次迭代中的表现就表现优秀，这表明我们的模型可以高精度的提取信息实例。

为了进一步展示论文中模型的有效性，文中还列出了一个例子，如下图所示：

![3](/img/adersarial/3.png)

在"Discovered"中一栏中，第一个实例黑体标出的是ACE-2005中的触发词，但语法不同，第二个实例是新发现的触发词，未从在ACE-2005数据集中出现过。在我们的扩展数据集中，有1.2%的触发词是新发现的。这表明我们的方法不仅可以从未标记数据中找到与标记数据中那些实例类似的新实例，还可以发现发现的触发词并大大扩展了数据集的覆盖范围。

### 参考

[Adversarial Training for Weakly Supervised Event Detection](https://www.aclweb.org/anthology/N19-1105)

